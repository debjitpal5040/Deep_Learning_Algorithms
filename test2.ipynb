{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import PyTorch and matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn  # nn contains all of PyTorch's building blocks for neural networks\n",
    "from torch.backends import mps\n",
    "\n",
    "# Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = \"mps\" if mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight and bias\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create range values\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.01\n",
    "\n",
    "# Create X and y (features and labels)\n",
    "X = torch.arange(start, end, step).unsqueeze(\n",
    "    dim=1\n",
    ")  # without unsqueeze, errors will happen later on (shapes within linear layers)\n",
    "y = weight * X + bias\n",
    "X, y = X.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1]), torch.Size([100, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([40, 13, 91, 58, 23, 80, 76, 59, 81, 78, 66, 84, 35, 69, 14,  1, 90, 87,\n",
      "         4, 31, 75, 71,  5, 63, 57, 21, 43,  2, 51, 73, 47, 36, 39, 32, 64, 61,\n",
      "        97, 49, 18, 85,  9, 26, 29,  3, 79, 19, 10, 34, 11, 96, 70, 83, 86, 44,\n",
      "        15, 74, 53, 20, 16, 56, 45, 48, 82, 54,  7, 41, 93,  6,  0, 95, 67, 88,\n",
      "        98, 37, 22, 94, 92, 77, 65, 99, 72,  8, 60, 12, 17, 46, 89, 68, 55, 50,\n",
      "        30, 28, 62, 27, 25, 33, 24, 38, 42, 52])\n",
      "80 20\n"
     ]
    }
   ],
   "source": [
    "# split data into train and test sets using pytorch\n",
    "a = torch.randperm(len(X))\n",
    "print(a)\n",
    "train_size = int(0.8 * len(X))\n",
    "test_size = len(X) - train_size\n",
    "print(train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([40, 13, 91, 58, 23, 80, 76, 59, 81, 78, 66, 84, 35, 69, 14,  1, 90, 87,\n",
      "         4, 31, 75, 71,  5, 63, 57, 21, 43,  2, 51, 73, 47, 36, 39, 32, 64, 61,\n",
      "        97, 49, 18, 85,  9, 26, 29,  3, 79, 19, 10, 34, 11, 96, 70, 83, 86, 44,\n",
      "        15, 74, 53, 20, 16, 56, 45, 48, 82, 54,  7, 41, 93,  6,  0, 95, 67, 88,\n",
      "        98, 37, 22, 94, 92, 77, 65, 99]) tensor([72,  8, 60, 12, 17, 46, 89, 68, 55, 50, 30, 28, 62, 27, 25, 33, 24, 38,\n",
      "        42, 52])\n"
     ]
    }
   ],
   "source": [
    "train_idx = a[:train_size]\n",
    "test_idx = a[-test_size:]\n",
    "print(train_idx, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(\n",
    "    train_data=X_train,\n",
    "    train_labels=y_train,\n",
    "    test_data=X_test,\n",
    "    test_labels=y_test,\n",
    "    predictions=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots training data, test data and compares predictions.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions in red (predictions were made on the test data)\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Note: If you've reset your runtime, this function won't work,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# you'll have to rerun the cell above where it's instantiated.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mplot_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mplot_predictions\u001b[0;34m(train_data, train_labels, test_data, test_labels, predictions)\u001b[0m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Plot training data in blue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot test data in green\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(test_data, test_labels, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/pyplot.py:3699\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3680\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m   3681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[1;32m   3682\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3697\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3698\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[0;32m-> 3699\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3711\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotnonfinite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotnonfinite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3716\u001b[0m     sci(__ret)\n\u001b[1;32m   3717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/axes/_axes.py:4652\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4649\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_unit_info([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, x), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, y)], kwargs)\n\u001b[1;32m   4650\u001b[0m \u001b[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001b[39;00m\n\u001b[1;32m   4651\u001b[0m \u001b[38;5;66;03m# unless its argument is a masked array.\u001b[39;00m\n\u001b[0;32m-> 4652\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4653\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m   4654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:6875\u001b[0m, in \u001b[0;36m_frommethod.__call__\u001b[0;34m(self, a, *args, **params)\u001b[0m\n\u001b[1;32m   6872\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m   6873\u001b[0m     a, args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], a\n\u001b[0;32m-> 6875\u001b[0m marr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6876\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   6877\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(marr), method_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:8299\u001b[0m, in \u001b[0;36masanyarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m   8297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, MaskedArray) \u001b[38;5;129;01mand\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m a\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   8298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m-> 8299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmasked_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2820\u001b[0m, in \u001b[0;36mMaskedArray.__new__\u001b[0;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order)\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;124;03mCreate a new masked array from scratch.\u001b[39;00m\n\u001b[1;32m   2813\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;66;03m# Process data.\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m _data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m                 \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2822\u001b[0m _baseclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_baseclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(_data))\n\u001b[1;32m   2823\u001b[0m \u001b[38;5;66;03m# Check that we're not erasing the mask.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: If you've reset your runtime, this function won't work,\n",
    "# you'll have to rerun the cell above where it's instantiated.\n",
    "plot_predictions(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LinearRegressionModelV2(\n",
       "   (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
       " ),\n",
       " OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
       "              ('linear_layer.bias', tensor([0.8300]))]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subclass nn.Module to make our model\n",
    "class LinearRegressionModelV2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use nn.Linear() for creating the model parameters\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
    "\n",
    "    # Define the forward computation (input data x flows through nn.Linear())\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "\n",
    "# Set the manual seed when creating the model (this isn't always need but is used for demonstrative purposes, try commenting it out and seeing what happens)\n",
    "torch.manual_seed(42)\n",
    "model_1 = LinearRegressionModelV2()\n",
    "model_1, model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model device\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set model to GPU if it's availalble, otherwise it'll default to CPU\n",
    "model_1.to(\n",
    "    device\n",
    ")  # the device variable was set above to be \"cuda\" if available or \"cpu\" if not\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    params=model_1.parameters(), lr=0.01  # optimize newly created model's parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.563180685043335 | Test loss: 0.5448959469795227\n",
      "Epoch: 10 | Train loss: 0.43676120042800903 | Test loss: 0.42335936427116394\n",
      "Epoch: 20 | Train loss: 0.31034165620803833 | Test loss: 0.30182287096977234\n",
      "Epoch: 30 | Train loss: 0.18392209708690643 | Test loss: 0.18028631806373596\n",
      "Epoch: 40 | Train loss: 0.05844947695732117 | Test loss: 0.061890292912721634\n",
      "Epoch: 50 | Train loss: 0.03864843770861626 | Test loss: 0.03527594730257988\n",
      "Epoch: 60 | Train loss: 0.0332099050283432 | Test loss: 0.028715819120407104\n",
      "Epoch: 70 | Train loss: 0.027912849560379982 | Test loss: 0.023689426481723785\n",
      "Epoch: 80 | Train loss: 0.022615788504481316 | Test loss: 0.018752168864011765\n",
      "Epoch: 90 | Train loss: 0.017327988520264626 | Test loss: 0.01435642410069704\n",
      "Epoch: 100 | Train loss: 0.012040871195495129 | Test loss: 0.00982564128935337\n",
      "Epoch: 110 | Train loss: 0.006752043962478638 | Test loss: 0.0052948701195418835\n",
      "Epoch: 120 | Train loss: 0.0014632176607847214 | Test loss: 0.0007640809053555131\n",
      "Epoch: 130 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n",
      "Epoch: 140 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n",
      "Epoch: 150 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n",
      "Epoch: 160 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n",
      "Epoch: 170 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n",
      "Epoch: 180 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n",
      "Epoch: 190 | Train loss: 0.0009101685136556625 | Test loss: 0.011132906191051006\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 200\n",
    "\n",
    "# Put data on the available device\n",
    "# Without this, error will happen (not all model/data on device)\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_1.train()  # train mode is on by default after construction\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_pred = model_1(X_train)\n",
    "\n",
    "    # 2. Calculate loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "    # 3. Zero grad optimizer\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Step the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_1.eval()  # put the model in evaluation mode for testing (inference)\n",
    "    # 1. Forward pass\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model_1(X_test)\n",
    "\n",
    "        # 2. Calculate the loss\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Train loss: {loss} | Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model learned the following values for weights and bias:\n",
      "OrderedDict([('linear_layer.weight', tensor([[0.6988]], device='mps:0')),\n",
      "             ('linear_layer.bias', tensor([0.3015], device='mps:0'))])\n",
      "\n",
      "And the original values for weights and bias are:\n",
      "weights: 0.7, bias: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Find our model's learned parameters\n",
    "from pprint import (\n",
    "    pprint,\n",
    ")  # pprint = pretty print, see: https://docs.python.org/3/library/pprint.html\n",
    "\n",
    "print(\"The model learned the following values for weights and bias:\")\n",
    "pprint(model_1.state_dict())\n",
    "print(\"\\nAnd the original values for weights and bias are:\")\n",
    "print(f\"weights: {weight}, bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8047],\n",
       "        [0.3574],\n",
       "        [0.7208],\n",
       "        [0.3854],\n",
       "        [0.4203],\n",
       "        [0.6230],\n",
       "        [0.9235],\n",
       "        [0.7767],\n",
       "        [0.6859],\n",
       "        [0.6509],\n",
       "        [0.5112],\n",
       "        [0.4972],\n",
       "        [0.7348],\n",
       "        [0.4902],\n",
       "        [0.4762],\n",
       "        [0.5321],\n",
       "        [0.4692],\n",
       "        [0.5671],\n",
       "        [0.5950],\n",
       "        [0.6649]], device='mps:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn model into evaluation mode\n",
    "model_1.eval()\n",
    "\n",
    "# Make predictions on the test data\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_1(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# plot_predictions(predictions=y_preds) # -> won't work... data not on CPU\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Put data on the CPU and plot it\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplot_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mplot_predictions\u001b[0;34m(train_data, train_labels, test_data, test_labels, predictions)\u001b[0m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Plot training data in blue\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Plot test data in green\u001b[39;00m\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(test_data, test_labels, c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/pyplot.py:3699\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3680\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mscatter)\n\u001b[1;32m   3681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter\u001b[39m(\n\u001b[1;32m   3682\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3697\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3698\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PathCollection:\n\u001b[0;32m-> 3699\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3701\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3702\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmarker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3709\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3711\u001b[0m \u001b[43m        \u001b[49m\u001b[43medgecolors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplotnonfinite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplotnonfinite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3716\u001b[0m     sci(__ret)\n\u001b[1;32m   3717\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/matplotlib/axes/_axes.py:4652\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4649\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_unit_info([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, x), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, y)], kwargs)\n\u001b[1;32m   4650\u001b[0m \u001b[38;5;66;03m# np.ma.ravel yields an ndarray, not a masked array,\u001b[39;00m\n\u001b[1;32m   4651\u001b[0m \u001b[38;5;66;03m# unless its argument is a masked array.\u001b[39;00m\n\u001b[0;32m-> 4652\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4653\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mravel(y)\n\u001b[1;32m   4654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39msize:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:6875\u001b[0m, in \u001b[0;36m_frommethod.__call__\u001b[0;34m(self, a, *args, **params)\u001b[0m\n\u001b[1;32m   6872\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m   6873\u001b[0m     a, args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], a\n\u001b[0;32m-> 6875\u001b[0m marr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6876\u001b[0m method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   6877\u001b[0m method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(marr), method_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:8299\u001b[0m, in \u001b[0;36masanyarray\u001b[0;34m(a, dtype)\u001b[0m\n\u001b[1;32m   8297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, MaskedArray) \u001b[38;5;129;01mand\u001b[39;00m (dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m a\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   8298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[0;32m-> 8299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmasked_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/ma/core.py:2820\u001b[0m, in \u001b[0;36mMaskedArray.__new__\u001b[0;34m(cls, data, mask, dtype, copy, subok, ndmin, fill_value, keep_mask, hard_mask, shrink, order)\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2812\u001b[0m \u001b[38;5;124;03mCreate a new masked array from scratch.\u001b[39;00m\n\u001b[1;32m   2813\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2817\u001b[0m \n\u001b[1;32m   2818\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2819\u001b[0m \u001b[38;5;66;03m# Process data.\u001b[39;00m\n\u001b[0;32m-> 2820\u001b[0m _data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2821\u001b[0m \u001b[43m                 \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2822\u001b[0m _baseclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_baseclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(_data))\n\u001b[1;32m   2823\u001b[0m \u001b[38;5;66;03m# Check that we're not erasing the mask.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:1062\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1062\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot_predictions(predictions=y_preds) # -> won't work... data not on CPU\n",
    "\n",
    "# Put data on the CPU and plot it\n",
    "plot_predictions(predictions=y_preds.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/01_pytorch_workflow_model_1.pth\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = \"01_pytorch_workflow_model_1.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(\n",
    "    obj=model_1.state_dict(),  # only saving the state_dict() only saves the models learned parameters\n",
    "    f=MODEL_SAVE_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model:\n",
      "LinearRegressionModelV2(\n",
      "  (linear_layer): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "Model on device:\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a fresh instance of LinearRegressionModelV2\n",
    "loaded_model_1 = LinearRegressionModelV2()\n",
    "\n",
    "# Load model state dict\n",
    "loaded_model_1.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "# Put model to target device (if your data is on GPU, model will have to be on GPU to make predictions)\n",
    "loaded_model_1.to(device)\n",
    "\n",
    "print(f\"Loaded model:\\n{loaded_model_1}\")\n",
    "print(f\"Model on device:\\n{next(loaded_model_1.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True],\n",
       "        [True]], device='mps:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate loaded model\n",
    "loaded_model_1.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_1_preds = loaded_model_1(X_test)\n",
    "y_preds == loaded_model_1_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
